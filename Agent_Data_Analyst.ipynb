{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# from openai import AsyncOpenAI\n",
    "\n",
    "# from agents import Agent, OpenAIChatCompletionsModel, Runner, function_tool, set_tracing_disabled, GuardrailFunctionOutput,InputGuardrail\n",
    "# from agents import (\n",
    "#     Agent,\n",
    "#     GuardrailFunctionOutput,\n",
    "#     InputGuardrailTripwireTriggered,\n",
    "#     RunContextWrapper,\n",
    "#     Runner,\n",
    "#     TResponseInputItem,\n",
    "#     input_guardrail,\n",
    "# )\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "# import json\n",
    "# from pydantic import BaseModel\n",
    "# from IPython.display import Markdown, display\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Always remember to do this!\n",
    "# load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the key prefixes to help with any debugging\n",
    "# gemini_api_key=os.getenv(\"GEMINI_API_KEY\")\n",
    "# groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "\n",
    "# if groq_api_key:\n",
    "#     print(f\"Groq API Key exists and begins {groq_api_key[:7]}\")\n",
    "# else:\n",
    "#     print(\"Groq API Key not set (and this is optional)\")\n",
    "\n",
    "# if gemini_api_key:\n",
    "#     print(f\"Gemini API Key exists and begins {gemini_api_key[:4]}\")\n",
    "# else:\n",
    "#     print(\"Gemini API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# openai = AsyncOpenAI(\n",
    "#     api_key=gemini_api_key,\n",
    "#     base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\" \n",
    "# )\n",
    "# model_name = \"gemini-1.5-flash-latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# openai = AsyncOpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "# model_name = \"gemma2-9b-it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Loading The Model \n",
    "# openai = AsyncOpenAI(base_url='http://localhost:11434/v1', api_key='ollama')#2 Billion Parameters Model\n",
    "# model_name = \"llama3.2:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_tracing_disabled(disabled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @function_tool\n",
    "# def get_check_new_recency(file_path):\n",
    "#     \"\"\"\n",
    "#     Analyzes customer transaction data to verify if the current segment assignment \n",
    "#     is valid based on the recency of their last transaction.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     file_path : str\n",
    "#         Path to the CSV file containing customer data. The file must contain the \n",
    "#         following columns:\n",
    "#             - 'CustomerId': Unique identifier for each customer\n",
    "#             - 'LastTransDate': Date of the customer's most recent transaction\n",
    "#             - 'Segment': The currently assigned segment for the customer\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     dict\n",
    "#         A dictionary keyed by `CustomerId` where each value is another dictionary \n",
    "#         containing:\n",
    "#             - 'Segment': Original segment from input data\n",
    "#             - 'Last Transaction Date': Parsed datetime of the last transaction\n",
    "#             - 'Assigned Segment': Original segment again (redundant but preserved)\n",
    "#             - 'Is Correct Assignment': bool, True if last transaction is within 50 days \n",
    "#               from the reference date (June 25, 2025), False otherwise\n",
    "\n",
    "#     Notes\n",
    "#     -----\n",
    "#     - The function reads the input CSV, drops rows with missing values, and computes \n",
    "#       the number of days since each customer's last transaction.\n",
    "#     - A reference date of June 25, 2025 is used to calculate recency.\n",
    "#     - A transaction is considered recent if it occurred within the last 50 days.\n",
    "#     - If the file does not exist, an empty dictionary is returned.\n",
    "#     - The `@function_tool` decorator suggests this function is used within a tool-based \n",
    "#       agent framework (e.g., OpenAI's function-calling system).\n",
    "#     \"\"\"\n",
    "#     if not os.path.exists(file_path):\n",
    "#         return {}\n",
    "#     df=pd.read_csv(file_path,index_col=0)\n",
    "#     df.dropna(inplace=True)\n",
    "#     # print(df)\n",
    "#     max_date=pd.to_datetime(\"2025-06-25\",format=\"%Y-%m-%d\")\n",
    "#     df[\"LastTransDate\"]=pd.to_datetime(df[\"LastTransDate\"],format=\"mixed\")\n",
    "#     df[\"DiffDays\"] = (max_date - pd.to_datetime(df[\"LastTransDate\"])).dt.days\n",
    "#     # print(df)\n",
    "#     df[\"LastTransDate\"]=df[\"LastTransDate\"].astype(str)\n",
    "\n",
    "#     final_summary_dict={}\n",
    "#     for index, row in df.iterrows():\n",
    "#         print(row[\"CustomerId\"])\n",
    "#         final_summary_dict[row[\"CustomerId\"]]={}\n",
    "#         final_summary_dict[row[\"CustomerId\"]][\"Segment\"]=row[\"Segment\"]\n",
    "#         new_flag=False\n",
    "#         if row[\"DiffDays\"]>50:\n",
    "#             new_flag=False\n",
    "#         else:\n",
    "#             new_flag=True\n",
    "#         final_summary_dict[row[\"CustomerId\"]][\"Last Transaction Date\"]=row[\"LastTransDate\"]\n",
    "#         final_summary_dict[row[\"CustomerId\"]][\"Assigned Segment\"]=row[\"Segment\"]\n",
    "#         final_summary_dict[row[\"CustomerId\"]][\"Is Correct Assignment\"]=new_flag\n",
    "#     return final_summary_dict\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @function_tool\n",
    "# def check_outlet_and_amount(file_path):\n",
    "#     \"\"\"\n",
    "#     Reads a CSV file and returns the CustomerId and OutletId associated with the highest transaction amount.\n",
    "\n",
    "#     Args:\n",
    "#         file_path (str): Path to the CSV file. The file must contain 'Amount', 'CustomerId', and 'OutletId' columns.\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary with keys 'CustomerId' and 'OutletId' for the transaction with the highest amount.\n",
    "#     \"\"\"\n",
    "   \n",
    "#     if not os.path.exists(file_path):\n",
    "#         return {}\n",
    "#     df=pd.read_csv(file_path,index_col=0)\n",
    "#     df.dropna(inplace=True)\n",
    "#     cust_with_max_amount=df[df[\"Amount\"]==df[\"Amount\"].max()][\"CustomerId\"].values[0]\n",
    "#     outlet_with_max_amount=df[df[\"Amount\"]==df[\"Amount\"].max()][\"OutletId\"].values[0]\n",
    "#     return {\"CustomerId\":cust_with_max_amount,\"OutletId\":outlet_with_max_amount}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_outlet_and_amount(r\"D:\\Project\\SelfLearning\\Generative AI\\Agents\\agents\\2_openai\\Sample_Agent_DF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FileTypeCheck(BaseModel):\n",
    "#     is_correct_file_type: bool\n",
    "#     reasoning: str\n",
    "\n",
    "# guardrail_agent = Agent( \n",
    "#     name=\"Guardrail check\",\n",
    "#     instructions=\"Check if the user is providing a valid file path and not a random string.\",\n",
    "#     output_type=FileTypeCheck,\n",
    "#     model=OpenAIChatCompletionsModel( \n",
    "#         model=model_name,\n",
    "#         openai_client=openai,\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# @input_guardrail\n",
    "# async def file_type_check_guardrail(ctx, guardrail_agent, input_data):\n",
    "#     # print(\"Inside GuardRail\")\n",
    "#     result = await Runner.run(guardrail_agent, input_data, context=ctx.context)\n",
    "#     print(\"Final Output\",result.final_output)\n",
    "#     return GuardrailFunctionOutput(\n",
    "#         output_info=result.final_output, \n",
    "#         tripwire_triggered=result.final_output.is_correct_file_type,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(guardrail_agent))\n",
    "# # Should output something like: <class 'agents.agent_wrapper.AgentWrapper'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_analyst_agent_1 = Agent(\n",
    "#     name=\"Data Analyst Agent 1\",\n",
    "#     instructions=\"As a Data Analyst Agent 1 ,You Only Check Recency of the Customer and Provide Your Assesment on it.\",\n",
    "#     model=OpenAIChatCompletionsModel( \n",
    "#         model=model_name,\n",
    "#         openai_client=openai,\n",
    "#     ),tools=[get_check_new_recency],    \n",
    "# )\n",
    "\n",
    "\n",
    "# data_analyst_agent_2 = Agent(\n",
    "#     name=\"Data Analyst Agent 2\",\n",
    "#     instructions=\"As a Data Analyst Agent 2 ,You Only Check Outlet and Amount of the Customer and Provide Your Assesment on it.\",\n",
    "#     model=OpenAIChatCompletionsModel( \n",
    "#         model=model_name,\n",
    "#         openai_client=openai,\n",
    "#     ),tools=[check_outlet_and_amount],    \n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# async def main(input, data_analyst_agent_1, data_analyst_agent_2):\n",
    "#     \"\"\"\n",
    "#     Routes input data to the appropriate agent based on the type of analysis required.\n",
    "\n",
    "#     Parameters:\n",
    "#         file_path (str): Path to the CSV file containing transaction or segmentation data.\n",
    "#         data_analyst_agent_1 (Agent): Agent to handle recency-related queries.\n",
    "#         data_analyst_agent_2 (Agent): Agent to handle outlet and amount-related queries.\n",
    "\n",
    "#     Returns:\n",
    "#         Any: The final output returned by the triage agent after delegating the task.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     triage_agent = Agent(\n",
    "#         name=\"Triage agent\",\n",
    "#         instructions=(\n",
    "#             \"Help the user with their questions. \"\n",
    "#             \"If the user asks about recency, hand off to the data_analyst_agent_1. \"\n",
    "#             \"If the user asks about outlet and amount, hand off to the data_analyst_agent_2.\"\n",
    "#         ),\n",
    "#         handoffs=[data_analyst_agent_1, data_analyst_agent_2],\n",
    "#     )\n",
    "\n",
    "#     # try:\n",
    "#     result = await Runner.run(triage_agent, input=input)\n",
    "#     # except InputGuardrailTripwireTriggered:\n",
    "#     #     print(\"Input Guardrail Tripwire Triggered\")\n",
    "\n",
    "#     return result.final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path=r\"D:\\Project\\SelfLearning\\Generative AI\\Agents\\agents\\2_openai\\Sample_Agent_DF.csv\"\n",
    "# input=f\"I want to know about the recency of the customer file path is {file_path}\"\n",
    "# final_output=await main(input,data_analyst_agent_1,data_analyst_agent_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Markdown(final_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "import pandas as pd\n",
    "from agents import (\n",
    "    RunResult,\n",
    "    Agent,\n",
    "    Runner,\n",
    "    function_tool,\n",
    "    Model,\n",
    "    ModelProvider,\n",
    "    OpenAIChatCompletionsModel,\n",
    "    set_tracing_disabled,\n",
    "    InputGuardrail,InputGuardrailTripwireTriggered,\n",
    "    GuardrailFunctionOutput,\n",
    "    input_guardrail,\n",
    "    RunContextWrapper,\n",
    "    TResponseInputItem)\n",
    "from pydantic import BaseModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_tracing_disabled(disabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OLLAMA_MODEL=\"qwen3:1.7b\"\n",
    "ollama_client=AsyncOpenAI(base_url=\"http://localhost:11434/v1\",api_key=\"ollama\")\n",
    "class OllamaProvider(ModelProvider):\n",
    "    def get_model(self, model_name=OLLAMA_MODEL) -> Model:\n",
    "        return OpenAIChatCompletionsModel(model=model_name,openai_client=ollama_client)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def get_check_dtypes():\n",
    "    \"\"\"Checks and returns the Data Types of the Dataframe\"\"\"\n",
    "    file_path=r\"D:\\Project\\SelfLearning\\Generative AI\\Agents\\agents\\2_openai\\Sample_Agent_DF.csv\"\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        return {}\n",
    "    df=pd.read_csv(file_path)\n",
    "    dtypes_dict=df.dtypes.to_dict()\n",
    "    return dtypes_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@function_tool\n",
    "def get_check_new_recency():\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    file_path=r\"D:\\Project\\SelfLearning\\Generative AI\\Agents\\agents\\2_openai\\Sample_Agent_DF.csv\"\n",
    "    df=pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "    # Convert to list of dicts\n",
    "    records = df.to_dict(orient='records')\n",
    "    df_records_str=  json.dumps(records, indent=4)\n",
    "\n",
    "    if df_records_str==\"\":\n",
    "        return {}\n",
    "    df_records = json.loads(df_records_str)\n",
    "\n",
    "    df = pd.DataFrame(df_records)\n",
    "    df.dropna(inplace=True)\n",
    "    print(df)\n",
    "    max_date=pd.to_datetime(\"2025-06-25\",format=\"%Y-%m-%d\")\n",
    "    df[\"LastTransDate\"]=pd.to_datetime(df[\"LastTransDate\"],format=\"mixed\")\n",
    "    df[\"DiffDays\"] = (max_date - pd.to_datetime(df[\"LastTransDate\"])).dt.days\n",
    "    # print(df)\n",
    "    df[\"LastTransDate\"]=df[\"LastTransDate\"].astype(str)\n",
    "\n",
    "    final_summary_dict={}\n",
    "    for index, row in df.iterrows():\n",
    "        print(row[\"CustomerId\"])\n",
    "        final_summary_dict[row[\"CustomerId\"]]={}\n",
    "        final_summary_dict[row[\"CustomerId\"]][\"Segment\"]=row[\"Segment\"]\n",
    "        new_flag=False\n",
    "        if row[\"DiffDays\"]>50:\n",
    "            new_flag=False\n",
    "        else:\n",
    "            new_flag=True\n",
    "        final_summary_dict[row[\"CustomerId\"]][\"Last Transaction Date\"]=row[\"LastTransDate\"]\n",
    "        final_summary_dict[row[\"CustomerId\"]][\"Assigned Segment\"]=row[\"Segment\"]\n",
    "        final_summary_dict[row[\"CustomerId\"]][\"Is Correct Assignment\"]=new_flag\n",
    "    return final_summary_dict\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_check_new_recency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@function_tool\n",
    "def get_check_amount():\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    file_path=r\"D:\\Project\\SelfLearning\\Generative AI\\Agents\\agents\\2_openai\\Sample_Agent_DF.csv\"\n",
    "    df=pd.read_csv(file_path)\n",
    "    # Convert to list of dicts\n",
    "    records = df.to_dict(orient='records')\n",
    "    df_records_str=  json.dumps(records, indent=4)\n",
    "    if df_records_str==\"\":\n",
    "        return {}\n",
    "    df_records = json.loads(df_records_str)\n",
    "\n",
    "    df = pd.DataFrame(df_records)\n",
    "    df.dropna(inplace=True)\n",
    "    print(df)\n",
    "    max_amt_df=df[df[\"Amount \"]==df[\"Amount \"].max()]\n",
    "    max_amt_cust=max_amt_df[\"CustomerId\"].to_list()[0]\n",
    "    max_amt=max_amt_df[\"Amount \"].to_list()[0]\n",
    "    print(f\"CustomerId With Maximum Amount is {max_amt_cust}\")\n",
    "    print(f\" Maximum Amount is {max_amt}\")\n",
    "    final_dict={\"Maximum Amount Spend\":max_amt,\"CustomerId\":max_amt_cust}\n",
    "    return final_dict\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_guardrail_instructions=\"\"\"Reject input if it appears to be gibberish, such as random characters or meaningless sequences. \n",
    "This includes:\n",
    "i.Nonsense strings without real words (e.g., 'asdjkl', 'zxcmnb')\n",
    "ii.Random combinations of letters and numbers that do not form valid words or sentences (e.g., '94ujnehiurwhoie')\n",
    "iii.Unintelligible or unstructured input that lacks grammatical structure or known language patterns.\n",
    "Accept only if the input is coherent, uses known words, or forms meaningful phrases or questions.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputGuardrailResponse(BaseModel):\n",
    "    isRandomString:bool\n",
    "    reasoning:str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_guardrail_agent = Agent(\n",
    "    name=\"Input GuardRail Agent\",\n",
    "    instructions=input_guardrail_instructions,\n",
    "    model=OllamaProvider.get_model(OLLAMA_MODEL),\n",
    "    output_type=InputGuardrailResponse\n",
    "    # tool_use_behavior = \"stop_on_first_tool\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@input_guardrail\n",
    "async def user_input_guardrail(ctx: RunContextWrapper[None], agent: Agent, input: str | list[TResponseInputItem]\n",
    ") -> GuardrailFunctionOutput:\n",
    "    result = await Runner.run(input_guardrail_agent, input, context=ctx.context)\n",
    "    print(\"Inside User Input Guardrail\")\n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info=result.final_output,\n",
    "        tripwire_triggered=not result.final_output.isRandomString\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analyst_agent_1 = Agent(\n",
    "    name=\"Data Analyst Agent 1\",\n",
    "    instructions=\"As a Data Analyst Agent 1 ,You Only Check Recency of the Customer and Provide Your Assesment on it.Plase Mention CustomerId Also From Your Assesment and Elaborate The Assesment\",\n",
    "    handoff_description=\"Specialist agent for Checking Recency\",\n",
    "    model=OllamaProvider.get_model(OLLAMA_MODEL)\n",
    "    ,tools=[get_check_new_recency],\n",
    "    # tool_use_behavior = \"stop_on_first_tool\")\n",
    ")\n",
    "\n",
    "data_analyst_agent_2 = Agent(\n",
    "    name=\"Data Analyst Agent 2\",\n",
    "    instructions=\"As a Data Analyst Agent 2 ,You Only Provide User With The Customer's Amount Spend related Information. Make Sure You Elaborate Your Answer.\",\n",
    "    handoff_description=\"Specialist agent for Customer's Amount\",\n",
    "\n",
    "    model=OllamaProvider.get_model(OLLAMA_MODEL)\n",
    "    ,tools=[get_check_amount],\n",
    "    tool_use_behavior = \"stop_on_first_tool\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "main_agent=Agent(\n",
    "    name=\"Operator Agent\",\n",
    "    instructions=\"As an Operator Agent You Determine Which agent to be used based on User's Question.If the you cannot Determine The Agent or the Question is not relative ,Give a Witty Reply\",\n",
    "    model=OllamaProvider.get_model(OLLAMA_MODEL)\n",
    "    ,handoffs=[data_analyst_agent_1,data_analyst_agent_2],\n",
    "    input_guardrails=[user_input_guardrail])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main(main_agent,data_analyst_agent_1,data_analyst_agent_2,input):\n",
    "    \"\"\"\n",
    "    Routes input data to the appropriate agent based on the type of analysis required.\n",
    "\n",
    "    Parameters:\n",
    "        df: DataFrame that contains Customer Related Information.\n",
    "        data_analyst_agent_1 (Agent): Agent to handle recency-related queries.\n",
    "        data_analyst_agent_2 (Agent):Agent to Handle Amount Related Queries.\n",
    "        main_agent:Orchestrator Agent\n",
    "        input:Query By User\n",
    "\n",
    "    Returns:\n",
    "        Any: The final output returned by the triage agent after delegating the task.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "    try:\n",
    "        result = await Runner.run(main_agent,input=input)\n",
    "        \n",
    "        if result or result.last_agent in [data_analyst_agent_1,data_analyst_agent_2]:\n",
    "            print(f\"Handing off to {result.last_agent.name}\")\n",
    "            sub_result=await Runner.run(result.last_agent,input=input)\n",
    "\n",
    "    except InputGuardrailTripwireTriggered as e:\n",
    "        print(f\"Input Guardrail Tripwire Triggered Handing off to {result.last_agent.name}\")\n",
    "\n",
    "    return sub_result.final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside User Input Guardrail\n",
      "   CustomerId LastTransDate Segment  Amount   Outlet\n",
      "0           1     6/17/2025     New      100   Pune \n",
      "1           2     6/18/2025     New      200  Mumbai\n",
      "2           3     6/19/2025     New       80  Nashik\n",
      "3           4     1/19/2025     New       90  Satara\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Handing off to Data Analyst Agent 1\n",
      "   CustomerId LastTransDate Segment  Amount   Outlet\n",
      "0           1     6/17/2025     New      100   Pune \n",
      "1           2     6/18/2025     New      200  Mumbai\n",
      "2           3     6/19/2025     New       80  Nashik\n",
      "3           4     1/19/2025     New       90  Satara\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "final_output=await main(main_agent,data_analyst_agent_1,data_analyst_agent_2,\"Tell me About The Recency of the Customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, let's break down the response. The user asked about the recency of customers. The tool call returned some data with CustomerIds 1, 2, 3, and 4. \n",
       "\n",
       "Looking at the data, CustomerIds 1, 2, and 3 have their last transaction dates in June 2025, which is recent. Their assigned segment is 'New', and the assignment is correct. However, CustomerId 4 has a last transaction date in January 2025, which is much older. The assigned segment for CustomerId 4 is 'New', but the assignment is incorrect. \n",
       "\n",
       "So, the recency metrics would show that Customers 1, 2, and 3 are recent, while Customer 4 is not. The assessment is that three customers are in the 'New' segment with recent transactions, but one is in the 'New' segment with an older transaction date, indicating a potential issue with their assignment. The main takeaway is the recency difference based on transaction dates.\n",
       "</think>\n",
       "\n",
       "The recency assessment for the customers is as follows:\n",
       "\n",
       "- **CustomerIds 1, 2, and 3** are in the **\"New\"** segment with recent transactions (last transaction date: June 2025). Their assignments are **correct**.\n",
       "- **CustomerId 4** is in the **\"New\"** segment but has an **older** last transaction date (January 2025). The assignment is **incorrect**.\n",
       "\n",
       "### Summary:\n",
       "- **Recent Customers (Segment: New):** 1, 2, 3  \n",
       "- **Out of Date Customer (Segment: New):** 4  \n",
       "- **Key Insight:** Customer 4's assignment appears to be incorrect despite being in the \"New\" segment, while the others are correctly classified as recent. \n",
       "\n",
       "Let me know if you need further analysis!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
